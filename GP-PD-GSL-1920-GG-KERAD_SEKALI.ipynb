{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('E:/Sistem Informasi 16/Materi kuliah/semester 7/week 1/DAMI/TUGAS_BESAR/BX-Users.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "books = pd.read_csv('E:/Sistem Informasi 16/Materi kuliah/semester 7/week 1/DAMI/TUGAS_BESAR/BX-Books.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "book_ratings = pd.read_csv('E:/Sistem Informasi 16/Materi kuliah/semester 7/week 1/DAMI/TUGAS_BESAR/BX-Book-Ratings.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data And Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = users.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "percent = (users.isnull().sum()/users.isnull().count()) \\\n",
    ".sort_values(ascending=False)\n",
    "\n",
    "missing_users = pd.concat([total, percent], axis=1, \\\n",
    "                          keys=['Total', 'Missing Percent'])\n",
    "\n",
    "missing_users['Missing Percent'] = \\\n",
    "missing_users['Missing Percent'].apply(lambda x: x * 100)\n",
    "\n",
    "missing_users.loc[missing_users['Missing Percent'] > 10][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Users: {len(users)}\\nBooks: {len(books)}\\nRatings: {len(book_ratings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.columns = users.columns.str.strip().str.lower().str.replace('-', '_')\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_users = users.user_id.nunique()\n",
    "all_users = users.user_id.count()\n",
    "print(f'No. of unique user_id entries: {uniq_users} | Total user_id entries: {all_users}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(users.user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.loc[(users.age<5) | (users.age>100), 'age'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(users.age.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a histogram of the Age field\n",
    "ax = users.age.hist(bins=10, figsize=(12,5))\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('counts')\n",
    "ax.set_xticks(range(0,110,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = users.age.value_counts().sort_index()\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.rcParams.update({'font.size': 15}) # Set larger plot font size\n",
    "plt.bar(u.index, u.values)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_null = users.age.isnull().sum()\n",
    "all_users = users.user_id.count()\n",
    "print(f'There are {age_null} empty age values in our set of {all_users} users (or {(age_null/all_users)*100:.2f}%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_expanded = users.location.str.split(',', 2, expand=True)\n",
    "user_location_expanded.columns = ['city', 'state', 'country']\n",
    "users = users.join(user_location_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.drop(columns=['location'], inplace=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cities = users.city.value_counts()[:10]\n",
    "print(f'The 10 cities with the most users are:\\n{top_cities}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_countries = users.country.value_counts()[:10]\n",
    "print(f'The 10 countries with the most users are:\\n{top_countries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_string_country = users[users.country == ''].country.count()\n",
    "nan_country = users.country.isnull().sum()\n",
    "print(f'There are {empty_string_country} entries with empty strings, and {nan_country} NaN entries in the Country field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.country.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.columns = books.columns.str.strip().str.lower().str.replace('-', '_')\n",
    "books.drop(columns=['image_url_s', 'image_url_m', 'image_url_l'], inplace=True) # hilangkan kolom image-url\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubah years kebentuk float\n",
    "books.year_of_publication = pd.to_numeric(books.year_of_publication, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NaN\n",
    "zero_yr = books[books.year_of_publication == 0].year_of_publication.count()\n",
    "nan_yr = books.year_of_publication.isnull().sum()\n",
    "print(f'There are {zero_yr} entries as \\'0\\', and {nan_yr} NaN entries in the Year of Publication field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isi semua tahun yang NaN dengan 0\n",
    "books.year_of_publication.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = books.year_of_publication.value_counts().sort_index()\n",
    "yr = yr.where(yr>5) \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.bar(yr.index, yr.values)\n",
    "plt.xlabel('Year of Publication')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_books = books[books.year_of_publication<1900] \n",
    "books_from_the_future = books[books.year_of_publication>2018]\n",
    "\n",
    "hist_books_mini = historical_books[['book_title', 'year_of_publication']]\n",
    "future_books_mini = books_from_the_future[['book_title', 'year_of_publication']]\n",
    "print(f'Historical books:\\n{hist_books_mini}')\n",
    "print('\\n')\n",
    "print(f'Future books:\\n{future_books_mini}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of books dataset before removal: {len(books)}')\n",
    "books = books.loc[~(books.isbn.isin(historical_books.isbn))]\n",
    "books = books.loc[~(books.isbn.isin(books_from_the_future.isbn))] \n",
    "print(f'Length of books dataset after removal: {len(books)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.publisher = books.publisher.str.replace('&amp', '&', regex=False)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_books = books.isbn.nunique()\n",
    "all_books = books.isbn.count()\n",
    "print(f'No. of unique books: {uniq_books} | All book entries: {all_books}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_publishers = books.publisher.value_counts()[:10]\n",
    "print(f'The 10 publishers with the most entries in the books table are:\\n{top_publishers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors = books.book_author.value_counts()[:10]\n",
    "print(f'The 10 authors with the most entries in the books table are:\\n{top_authors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_string_publisher = books[books.publisher == ''].publisher.count()\n",
    "nan_publisher = books.publisher.isnull().sum()\n",
    "print(f'There are {empty_string_publisher} entries with empty strings, and {nan_publisher} NaN entries in the Publisher field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_string_author = books[books.book_author == ''].book_author.count()\n",
    "nan_author = books.book_author.isnull().sum()\n",
    "print(f'There are {empty_string_author} entries with empty strings, and {nan_author} NaN entries in the Author field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_titles = books.book_title.value_counts()[:10]\n",
    "print(f'The 10 book titles with the most entries in the books table are:\\n{top_titles}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books[books.book_title=='Jane Eyre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratings.columns = book_ratings.columns.str.strip().str.lower().str.replace('-', '_')\n",
    "book_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_users = book_ratings.groupby('user_id').isbn.count().sort_values(ascending=False)\n",
    "print(f'The 20 users with the most ratings:\\n{super_users[:20]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist = super_users.where(super_users<50)\n",
    "user_hist.hist(bins=30)\n",
    "plt.xlabel('No. of ratings')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_user_hist = super_users.where(super_users>1000)\n",
    "super_user_hist.hist(bins=30)\n",
    "plt.xlabel('No. of ratings (min. 1000)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtg = book_ratings.book_rating.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.rcParams.update({'font.size': 15}) # Set larger plot font size\n",
    "plt.bar(rtg.index, rtg.values)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Size of book_ratings before removing zero ratings: {len(book_ratings)}')\n",
    "book_ratings = book_ratings[book_ratings.book_rating != 0]\n",
    "print(f'Size of book_ratings after removing zero ratings: {len(book_ratings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtg = book_ratings.book_rating.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.bar(rtg.index, rtg.values)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Books table size: {len(books)}')\n",
    "print(f'Ratings table size: {len(book_ratings)}')\n",
    "books_with_ratings = book_ratings.join(books.set_index('isbn'), on='isbn')\n",
    "print(f'New table size: {len(books_with_ratings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_with_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {books_with_ratings.book_title.isnull().sum()} books with no title/author information.')\n",
    "print(f'This represents {len(books_with_ratings)/books_with_ratings.book_title.isnull().sum():.2f}% of the ratings dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_with_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_with_ratings.dropna(subset=['book_title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rtg = books_with_ratings.groupby('book_title').book_rating.sum()\n",
    "cm_rtg = cm_rtg.sort_values(ascending=False)[:10]\n",
    "idx = cm_rtg.index.tolist() \n",
    "vals = cm_rtg.values.tolist()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.bar(range(len(idx)), vals)\n",
    "plt.xticks(range(len(idx)), idx, rotation='vertical')\n",
    "plt.ylabel('cumulative rating score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = books_with_ratings.book_title.value_counts()\n",
    "mean_rtg = books_with_ratings[books_with_ratings.book_title.isin(cutoff[cutoff>50].index)].groupby('book_title')['book_rating'].mean()\n",
    "mean_rtg.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rtg.sort_values(ascending=False)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_with_ratings.groupby('book_title').isbn.nunique().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_isbns = books_with_ratings.groupby('book_title').isbn.nunique()\n",
    "multiple_isbns.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_mult_isbns = multiple_isbns.where(multiple_isbns>1)\n",
    "has_mult_isbns.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(has_mult_isbns)} book titles with multiple ISBN numbers which we will try to re-assign to a unique identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_mult_isbns['Jane Eyre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multiple_isbn_dict.pickle', 'rb') as handle:\n",
    "    multiple_isbn_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are now {len(multiple_isbn_dict)} books in the ISBN dictionary that have multiple ISBN numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of Jane Eyre dict entry: {len(multiple_isbn_dict[\"Jane Eyre\"])}\\n')\n",
    "multiple_isbn_dict['Jane Eyre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unique_isbn_col(df):\n",
    "    df['unique_isbn'] = df.apply(lambda row: multiple_isbn_dict[row.book_title][0] if row.book_title in multiple_isbn_dict.keys() else row.isbn, axis=1)\n",
    "    return df\n",
    "\n",
    "%time books_with_ratings = add_unique_isbn_col(books_with_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_with_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_with_ratings[books_with_ratings.book_title=='Jane Eyre'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Books+Ratings table size: {len(books_with_ratings)}')\n",
    "print(f'Users table size: {len(users)}')\n",
    "books_users_ratings = books_with_ratings.join(users.set_index('user_id'), on='user_id')\n",
    "print(f'New \"books_users_ratings\" table size: {len(books_users_ratings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_users_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_users_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_users_ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build Modelling Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_rating = books_users_ratings[['user_id', 'unique_isbn', 'book_rating']]\n",
    "user_item_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_rating1 = user_item_rating.sample(n=10000, random_state=42)\n",
    "user_item_rating1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtg = user_item_rating1.book_rating.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.bar(rtg.index, rtg.values)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "train_data, test_data = model_selection.train_test_split(user_item_rating1, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training set size: {len(train_data)}')\n",
    "print(f'Testing set size: {len(test_data)}')\n",
    "print(f'Test set is {(len(test_data)/(len(train_data)+len(test_data))*100):.0f}% of the full dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING SET\n",
    "u_unique_train = train_data.user_id.unique()\n",
    "train_data_user2idx = {o:i for i, o in enumerate(u_unique_train)}\n",
    "b_unique_train = train_data.unique_isbn.unique()\n",
    "train_data_book2idx = {o:i for i, o in enumerate(b_unique_train)}\n",
    "\n",
    "### TESTING SET\n",
    "u_unique_test = test_data.user_id.unique()\n",
    "test_data_user2idx = {o:i for i, o in enumerate(u_unique_test)}\n",
    "b_unique_test = test_data.unique_isbn.unique()\n",
    "test_data_book2idx = {o:i for i, o in enumerate(b_unique_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING SET\n",
    "train_data['u_unique'] = train_data['user_id'].map(train_data_user2idx)\n",
    "train_data['b_unique'] = train_data['unique_isbn'].map(train_data_book2idx)\n",
    "\n",
    "### TESTING SET\n",
    "test_data['u_unique'] = test_data['user_id'].map(test_data_user2idx)\n",
    "test_data['b_unique'] = test_data['unique_isbn'].map(test_data_book2idx)\n",
    "\n",
    "train_data = train_data[['u_unique', 'b_unique', 'book_rating']]\n",
    "test_data = test_data[['u_unique', 'b_unique', 'book_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING SET\n",
    "n_users = train_data['u_unique'].nunique()\n",
    "n_books = train_data['b_unique'].nunique()\n",
    "\n",
    "train_matrix = np.zeros((n_users, n_books))\n",
    "\n",
    "for entry in train_data.itertuples(): \n",
    "    train_matrix[entry[1]-1, entry[2]-1] = entry[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING SET\n",
    "n_users = test_data['u_unique'].nunique()\n",
    "n_books = test_data['b_unique'].nunique()\n",
    "\n",
    "test_matrix = np.zeros((n_users, n_books))\n",
    "\n",
    "for entry in test_data.itertuples(): \n",
    "    test_matrix[entry[1]-1, entry[2]-1] = entry[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_small = train_matrix[:10000, :10000]\n",
    "test_matrix_small = test_matrix[:10000, :10000]\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_matrix_small, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_matrix_small.T, metric='cosine') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction = predict(train_matrix_small, item_similarity, type='item')\n",
    "user_prediction = predict(train_matrix_small, user_similarity, type='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(prediction, test_matrix):\n",
    "    prediction = prediction[test_matrix.nonzero()].flatten()\n",
    "    test_matrix = test_matrix[test_matrix.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, test_matrix))\n",
    "\n",
    "# Call on test set to get error from each approach ('user' or 'item')\n",
    "print(f'User-based CF RMSE: {rmse(user_prediction, test_matrix_small)}')\n",
    "print(f'Item-based CF RMSE: {rmse(item_prediction, test_matrix_small)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_rating1.head() # lihat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "data = Dataset.load_from_df(user_item_rating1, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, NMF, model_selection, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVD()\n",
    "\n",
    "%time model_selection.cross_validate(model, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = model_selection.train_test_split(data, test_size=0.2)\n",
    "\n",
    "model = SVD()\n",
    "\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF()\n",
    "%time model_selection.cross_validate(model, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = model_selection.train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_factors': [80, 100, 120], 'lr_all': [0.001, 0.005, 0.01], 'reg_all': [0.01, 0.02, 0.04]}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gs.best_estimator['rmse']\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.cross_validate(model, data, measures=['rmse', 'mae'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVD(n_factors=80, lr_all=0.005, reg_all=0.04)\n",
    "model.fit(trainset) \n",
    "test_pred = model.test(testset)\n",
    "print(\"SVD : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 276744  # user_id\n",
    "iid = '038550120X' # unique_isbn\n",
    "\n",
    "pred = model.predict(uid, iid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The estimated rating for the book with the \"unique_isbn\" code {pred.iid} from user #{pred.uid} is {pred.est:.2f}.\\n')\n",
    "actual_rtg = user_item_rating1[(user_item_rating1.user_id==pred.uid) & (user_item_rating1.unique_isbn==pred.iid)].book_rating.values[0]\n",
    "print(f'The real rating given for this was {actual_rtg:.2f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ambil prediksi yang spesifik\n",
    "uid = 95095  # user_id\n",
    "iid = '0140079963' # unique_isbn\n",
    "\n",
    "pred = model.predict(uid, iid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The estimated rating for the book with the \"unique_isbn\" code {pred.iid} from user #{pred.uid} is {pred.est:.2f}.\\n')\n",
    "actual_rtg = user_item_rating1[(user_item_rating1.user_id==pred.uid) & (user_item_rating1.unique_isbn==pred.iid)].book_rating.values[0]\n",
    "print(f'The real rating given for this was {actual_rtg:.2f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=5):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "        \n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.test(testset)\n",
    "top_n = get_top_n(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_rating1.sort_values(['user_id', 'book_rating'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve books_users_ratings\n",
    "def get_reading_list(userid):\n",
    "    \n",
    "    reading_list = defaultdict(list)\n",
    "    top_n = get_top_n(predictions, n=10)\n",
    "    for n in top_n[userid]:\n",
    "        book, rating = n\n",
    "        title = books_users_ratings.loc[books_users_ratings.unique_isbn==book].book_title.unique()[0]\n",
    "        reading_list[title] = rating\n",
    "    return reading_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ambil acak user_id\n",
    "example_reading_list = get_reading_list(userid=278418)\n",
    "for book, rating in example_reading_list.items():\n",
    "    print(f'{book}: {rating}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
